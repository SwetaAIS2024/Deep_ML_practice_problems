# KL Divergence Between Two Normal Distributions
# Task: Implement KL Divergence Between Two Normal Distributions
# Your task is to compute the Kullback-Leibler (KL) divergence between two normal distributions. 
# KL divergence measures how one probability distribution differs from a second, reference probability distribution.
# Write a function kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q) that calculates the KL divergence between two 
# normal distributions, where ( P \sim N(\mu_P, \sigma_P^2) ) and ( Q \sim N(\mu_Q, \sigma_Q^2) ).
# The function should return the KL divergence as a floating-point number.